{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "#                                             #\n",
    "#                  READ ME                    #\n",
    "#                                             #\n",
    "###############################################\n",
    "#\n",
    "# This file is broken into three parts.\n",
    "#\n",
    "#   1. Importing necessary libraries and data\n",
    "#   2. The training and testing of a new model\n",
    "#   3. Loading in a previously trained model to test on some data\n",
    "#\n",
    "# In order to run parts 2 or 3, you will need to run part 1\n",
    "#\n",
    "# Any questions or issues email me:\n",
    "#       robe1157@msu.edu\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "#                                             #\n",
    "#                  PART ONE                   #\n",
    "#                                             #\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Basic libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import anndata as ad\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other libraries that are required to run\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import logging\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy.sparse import csc_matrix\n",
    "import magic\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SET YOUR NEEDED PATHS\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# YOU ONLY NEED THESE TWO LINES IF TRAINING A NEW MODEL\n",
    "train_gex = ad.read_h5ad(\"Gex_processed_training.h5ad\") #gex is gene expression which are RNA; Training data input\n",
    "train_adt = ad.read_h5ad(\"Adt_processed_training.h5ad\") # adt is protein; Training data response\n",
    "\n",
    "\n",
    "# IF ALL YOU NEED IS TO LOAD TESTING DATA THEN USE THESE LINE AND COMMENT THE OTHERS OUT\n",
    "test_gex = ad.read_h5ad(\"Gex_processed_testing.h5ad\") #gex is gene expression which are RNA; Training data input\n",
    "test_adt = ad.read_h5ad(\"Adt_processed_testing.h5ad\") # adt is protein; Training data response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will get passed to the method\n",
    "input_train_gex = train_gex\n",
    "input_train_adt = train_adt\n",
    "input_test_gex =  test_gex\n",
    "\n",
    "# This will get passed to the metric\n",
    "true_test_adt =  test_adt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(true_test_adt, pred_test_adt):\n",
    "    return  mean_squared_error(true_test_adt.X.toarray(), pred_test_adt.X, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "#                                             #\n",
    "#                  PART TWO                   #\n",
    "#                                             #\n",
    "###############################################\n",
    "\n",
    "# Do not run if you aren't looking to train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Performing dimensionality reduction on GEX values...\n"
     ]
    }
   ],
   "source": [
    "# Do PCA on the input data\n",
    "'''Baseline method training a linear regressor on the input data'''\n",
    "input_gex = ad.concat(\n",
    "    {\"train\": input_train_gex, \"test\": input_test_gex},\n",
    "    axis = 0,\n",
    "    join = \"outer\",\n",
    "    label = \"group\",\n",
    "    fill_value = 0,\n",
    "    index_unique = \"-\", \n",
    ")\n",
    "\n",
    "# Do PCA on the input data\n",
    "n = 50\n",
    "logging.info('Performing dimensionality reduction on GEX values...')\n",
    "embedder_gex = TruncatedSVD(n_components=n)\n",
    "gex_pca = embedder_gex.fit_transform(input_gex.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pca_model.pkl', 'wb') as f:\n",
    "    pickle.dump(embedder_gex, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_linear(input_train_gex, input_train_adt, input_test_gex):\n",
    "    '''Baseline method training a linear regressor on the input data'''\n",
    "    input_gex = ad.concat(\n",
    "        {\"train\": input_train_gex, \"test\": input_test_gex},\n",
    "        axis = 0,\n",
    "        join = \"outer\",\n",
    "        label = \"group\",\n",
    "        fill_value = 0,\n",
    "        index_unique = \"-\", \n",
    "    )\n",
    "    \n",
    "    # Do PCA on the input data\n",
    "    n = 50\n",
    "    logging.info('Performing dimensionality reduction on GEX values...')\n",
    "    embedder_gex = TruncatedSVD(n_components=n)\n",
    "    gex_pca = embedder_gex.fit_transform(input_gex.X)\n",
    "        \n",
    "    \n",
    "    # split dimension reduction GEX back up for training\n",
    "    X_train = gex_pca[input_gex.obs['group'] == 'train']\n",
    "    X_test = gex_pca[input_gex.obs['group'] == 'test']\n",
    "    y_train = input_train_adt.X.toarray()\n",
    "\n",
    "    assert len(X_train) + len(X_test) == len(gex_pca)\n",
    "    \n",
    "    logging.info('Running Linear regression...')\n",
    "    \n",
    "    reg = Ridge()\n",
    "    \n",
    "    # Train the model on the PCA reduced gex 1 and 2 data   \n",
    "    # Hyperparameters for our network\n",
    "    input_size = n\n",
    "    hidden_sizes = [5000,500,100]\n",
    "    output_size = 134\n",
    "\n",
    "    # Build a feed-forward network\n",
    "    model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                          nn.BatchNorm1d(hidden_sizes[0]),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                          nn.BatchNorm1d(hidden_sizes[1]),\n",
    "\t\t\t  nn.ReLU(),\n",
    "\t\t\t  nn.Linear(hidden_sizes[1], hidden_sizes[2]),\n",
    "                          nn.BatchNorm1d(hidden_sizes[2]),\n",
    "                          nn.Sigmoid(),\n",
    "                          nn.Linear(hidden_sizes[2], output_size))\n",
    "    print(model)\n",
    "\n",
    "    print(\"Building tensor objects\")\n",
    "\n",
    "    X_train_tensor = torch.Tensor(X_train)\n",
    "    y_train_tensor = torch.Tensor(y_train)\n",
    "    X_test_tensor  = torch.Tensor(X_test)\n",
    "    #y_test_tensor  = torch.Tensor(y_test)\n",
    "\n",
    "    mydata_train = TensorDataset(X_train_tensor,y_train_tensor)\n",
    "    #mydata_test  = TensorDataset(X_test_tensor,y_test_tensor)\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(mydata_train, batch_size=20, shuffle=True, drop_last=True)\n",
    "    #testloader = torch.utils.data.DataLoader(mydata_test, batch_size=10, shuffle=True, drop_last=True)\n",
    "\n",
    "    criterion = nn.MSELoss()# Optimizers require the parameters to optimize and a learning rate\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "    epochs = 15\n",
    " \n",
    "    print(\"Running epochs\")\n",
    "\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "        for data, target in trainloader:\n",
    "\n",
    "            # Training pass\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(data) #<--- note this line is using the model you set up at the beginning of this section\n",
    "            output = output.float()\n",
    "            target = target.float()\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        else:\n",
    "            print(f\"Training loss: {running_loss/len(trainloader)}\")\n",
    "    \n",
    "    predict = model(X_test_tensor)\n",
    "    y_pred = predict.detach().numpy()\n",
    "\n",
    " \n",
    "    # Project the predictions back to the adt feature space\n",
    "    \n",
    "    pred_test_adt = ad.AnnData(\n",
    "        X = y_pred,\n",
    "        obs = input_test_gex.obs,\n",
    "        var = input_train_adt.var,\n",
    "    \n",
    "    )\n",
    "    \n",
    "    # Add the name of the method to the result\n",
    "    pred_test_adt.uns[\"method\"] = \"linear\"\n",
    "    \n",
    "    return pred_test_adt\n",
    "\n",
    "# Run prediction\n",
    "pred_test_adt = baseline_linear(input_train_gex, input_train_adt, input_test_gex)\n",
    "# Calculate RMSE\n",
    "rmse = calculate_rmse(true_test_adt, pred_test_adt)\n",
    "# Print results\n",
    "print(f'{pred_test_adt.uns[\"method\"]} had a RMSE of {rmse:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "#                                             #\n",
    "#                PART THREE                   #\n",
    "#                                             #\n",
    "###############################################\n",
    "\n",
    "# Here we will be loading in PCA and Pytorch models then run the model on the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the path to the saved model\n",
    "PATH = \"mlp_01/model_01.pth\"\n",
    "# specify the path to the PCA model\n",
    "PCA_PATH = 'mlp_01/pca_model.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=50, out_features=5000, bias=True)\n",
      "  (1): BatchNorm1d(5000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): Linear(in_features=5000, out_features=5000, bias=True)\n",
      "  (4): BatchNorm1d(5000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=5000, out_features=5000, bias=True)\n",
      "  (7): BatchNorm1d(5000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (8): Tanh()\n",
      "  (9): Linear(in_features=5000, out_features=134, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Build a new instance of the model \n",
    "# Hyperparameters for our network\n",
    "input_size = 50\n",
    "hidden_sizes = [5000,5000,5000]\n",
    "output_size = 134\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                        nn.BatchNorm1d(hidden_sizes[0]),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                        nn.BatchNorm1d(hidden_sizes[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_sizes[1], hidden_sizes[2]),\n",
    "                        nn.BatchNorm1d(hidden_sizes[2]),\n",
    "                        nn.Tanh(),\n",
    "                        nn.Linear(hidden_sizes[2], output_size))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD IN MODEL\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()\n",
    "\n",
    "# LOAD IN PCA\n",
    "with open(PCA_PATH, 'rb') as f:\n",
    "    pca = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the testing data\n",
    "X_test = pca.transform(input_test_gex.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model on the fitted data\n",
    "X_test_tensor  = torch.Tensor(X_test)\n",
    "\n",
    "predict = model(X_test_tensor)\n",
    "y_pred = predict.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3591859631554783"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate RMSE\n",
    "mean_squared_error(true_test_adt.X.toarray(), y_pred, squared = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python dance-env",
   "language": "python",
   "name": "dance-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
